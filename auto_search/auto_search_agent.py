import os
import json


from config import SAVE_DATA_DIR
from llms_api import LlmBox
from tools import identify_model, convert_keyword
from function_calls import get_answer, SupportFunctionCallList

class AutoSearchAgent:
    def __init__(self):
        self.llm_box = LlmBox()

    def run_conversation(self,
                         messages,
                         functions_list=None,
                         tool_choice='auto',
                         verbose=False) -> str:
        """
        èƒ½å¤Ÿè‡ªåŠ¨æ‰§è¡Œå¤–éƒ¨å‡½æ•°è°ƒç”¨çš„Chatå¯¹è¯æ¨¡å‹
        :param messages: å¿…è¦å‚æ•°ï¼Œå­—å…¸ç±»å‹ï¼Œè¾“å…¥åˆ°Chatæ¨¡å‹çš„messageså‚æ•°å¯¹è±¡
        :param functions_list: å¯é€‰å‚æ•°ï¼Œé»˜è®¤ä¸ºNoneï¼Œå¯ä»¥è®¾ç½®ä¸ºåŒ…å«å…¨éƒ¨å¤–éƒ¨å‡½æ•°çš„åˆ—è¡¨å¯¹è±¡
        :param tool_choice: æ˜¯å¦è°ƒç”¨å¤–éƒ¨å·¥å…·
        :param verbose: æ˜¯å¦è¿›è¡Œè¿‡ç¨‹çš„æ‰“å°
        :returnï¼šChatæ¨¡å‹è¾“å‡ºç»“æœ
        """
        # å¦‚æœæ²¡æœ‰å¤–éƒ¨å‡½æ•°åº“ï¼Œåˆ™æ‰§è¡Œæ™®é€šçš„å¯¹è¯ä»»åŠ¡
        if functions_list is None:
            response_message = self.llm_box.chat(messages=messages)
            final_response = response_message.content

        # è‹¥å­˜åœ¨å¤–éƒ¨å‡½æ•°åº“ï¼Œåˆ™éœ€è¦çµæ´»é€‰å–å¤–éƒ¨å‡½æ•°å¹¶è¿›è¡Œå›ç­”
        else:
            # åˆ›å»ºfunctionså¯¹è±¡
            functions = SupportFunctionCallList
            # åˆ›å»ºå¤–éƒ¨å‡½æ•°åº“å­—å…¸
            available_functions = {func.__name__: func for func in functions_list}

            # first response
            response_message =  self.llm_box.chat(messages=messages,
                                                  tools=functions,
                                                  tool_choice=tool_choice)
            if verbose:
                print(f"{functions=}")
                print(f"{response_message=}")

            # åˆ¤æ–­è¿”å›ç»“æœæ˜¯å¦å­˜åœ¨function_callï¼Œå³åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å¤–éƒ¨å‡½æ•°æ¥å›ç­”é—®é¢˜
            if response_message.tool_calls:
                # éœ€è¦è°ƒç”¨å¤–éƒ¨å‡½æ•°
                # è·å–å‡½æ•°å
                function_name = response_message.tool_calls[0].function.name
                # è·å–å‡½æ•°å¯¹è±¡
                fuction_to_call = available_functions[function_name]
                # è·å–å‡½æ•°å‚æ•°
                function_args = json.loads(response_message.tool_calls[0].function.arguments)
                # å°†å‡½æ•°å‚æ•°è¾“å…¥åˆ°å‡½æ•°ä¸­ï¼Œè·å–å‡½æ•°è®¡ç®—ç»“æœ
                function_response = fuction_to_call(**function_args)

                if verbose:
                    print(f"{function_name=}\n{function_args=}\n{function_response=}")

                # messagesä¸­æ‹¼æ¥first responseæ¶ˆæ¯
                messages.append(response_message)
                # messagesä¸­æ‹¼æ¥å‡½æ•°è¾“å‡ºç»“æœ
                md_prompt = "\n\næœ€åä»¥markdownæ ¼å¼è¿›è¡Œè¾“å‡ºã€‚"

                messages.append(
                    {
                        "role": "tool",
                        "content": function_response + md_prompt,
                        'tool_call_id': response_message.tool_calls[0].id,
                    }
                )
                # ç¬¬äºŒæ¬¡è°ƒç”¨æ¨¡å‹
                second_response = self.llm_box.chat(messages=messages)
                # è·å–æœ€ç»ˆç»“æœ
                final_response = second_response.content
            else:
                final_response = response_message.content

        del messages

        return final_response

    def save_report(self, query:str, answer:str):
        '''è¿›è¡ŒæŠ¥å‘Šç»“æœçš„ä¿å­˜'''
        save_path = os.path.join(SAVE_DATA_DIR, f'report_{query}.md')
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write(answer)


    def sample_run(self, query:str,
                   use_search:bool=True,
                   use_keyword:bool=True,
                   save_report:bool=True):
        '''
        :param query: è¾“å…¥çš„éœ€è¦æœç´¢çš„é—®é¢˜
        :param use_search: æ˜¯å¦å¯åŠ¨è”ç½‘æœç´¢
        :param use_keyword: æ˜¯å¦å°†ç”¨æˆ·çš„æœç´¢å…ˆè¿›è¡Œå…³é”®è¯æå–
        :return: æœç´¢ç»“æœ
        '''
        if use_keyword:
            query = convert_keyword(query, self.llm_box)
            print(f">>> ğŸ¤–: æå–åˆ°æœç´¢å…³é”®è¯:{query}")

        # è°ƒç”¨åˆ¤åˆ«æ¨¡å‹
        if (response:= identify_model(query, llm_box=self.llm_box)) is not None:
            print(f">>> ğŸ¤–: {response}")
            return response

        if use_search:
            tool_choice = {"type": "function","function": {"name": "get_answer"}}
        else:
            tool_choice = 'auto'

        print(">>> æ­£åœ¨è°ƒç”¨å¤–éƒ¨æœç´¢å·¥å…·...")
        answer = self.run_conversation(
            messages=[{"role": "user", "content": query}],
            functions_list=[get_answer],
            tool_choice=tool_choice
        )

        if save_report:
            self.save_report(query, answer)

        return answer


    def chat(self, query="ä½ å¥½å‘€", system_message=None):
        if system_message is None:
            system_message = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä½ç™¾ç§‘é—®ç­”åŠ©æ‰‹ã€‚"}]
        messages = system_message
        messages.append({"role": "user", "content": query})

        while True:
            print(f">>> ğŸ‘¤: {query}")
            answer = self.sample_run(query)
            print(f">>> ğŸ¤–: {answer}")

            # è¯¢é—®ç”¨æˆ·æ˜¯å¦è¿˜æœ‰å…¶ä»–é—®é¢˜
            query = input(">>> ğŸ¤–: æ‚¨è¿˜æœ‰å…¶ä»–é—®é¢˜å—ï¼Ÿ(è¾“å…¥é€€å‡ºä»¥ç»“æŸå¯¹è¯): ")
            if query == "é€€å‡º":
                del messages
                break

            # è®°å½•ç”¨æˆ·å›ç­”
            messages.append({"role": "user", "content": query})

